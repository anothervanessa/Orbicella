[
  {
    "objectID": "orbicella_quarto_nb.html",
    "href": "orbicella_quarto_nb.html",
    "title": "Orbicella Analysis of Hybridization- Medina Lab Penn State University",
    "section": "",
    "text": "body-header: | This page brought to you by https://www.eurekalert.org/multimedia/927876 margin-header: |\nWe are running an ABBA-BABA test for hybridaztion in the Orbicella species complex. The test requires a VCF file containing variants for each species against a reference (in our case, we will use the outgroup Cyphastrea as the reference), a species tree in Newik format, and a file specifying the sample-name/species pair. I was provided with genomes for O.faveolata, O. annularis, and O. franksi. I was also provided with a metagenome for Cyphastrea.\nRight now, my first task is to create/find a pipeline to merge the VCF files produced from the pairwise SNP-calling in MUMmer(nucmer) into a single VCF file of SNP sites shared between the three species."
  },
  {
    "objectID": "orbicella_quarto_nb.html#variant-calling",
    "href": "orbicella_quarto_nb.html#variant-calling",
    "title": "Orbicella Analysis of Hybridization- Medina Lab Penn State University",
    "section": "Variant Calling",
    "text": "Variant Calling\nWe are conducting variant calling with Nucmer because it is a fast and efficient tool for variant calling between two genome assemblies. Raul said it is the only tool he is aware of for aligning multiple sequences against multiple sequences.\n\n# This code calls the SNPs between the query and ref (O.fav). The\n# ref will later be changed to Cyphastrea.\n\nnucmer -c 100 -p sp1 Orbicella_faveolata_cds.fna Orbicella_annularis_cds.fna\nnucmer -c 100 -p sp2 Orbicella_faveolata_cds.fna Orbicella_franksi_cds.fna\ndelta-filter -r -q sp1.delta > sp1.filter\ndelta-filter -r -q sp2.delta > sp2.filter\n\n# Option -T is required for input to all2vcf program\nshow-snps -T sp1.filter > sp1_T.snps\nshow-snps -T sp2.filter > sp2_T.snps\n\nNucmer only outputs .snps files, so I am using this script to transform the data into VCF format: https://github.com/MatteoSchiavinato/all2vcf\n\n./all2vcf mummer --snps sp1_T.snps --reference Orbicella_faveolata_cds.fna --type SNP --input-header --no-Ns > sp1.vcf\n./all2vcf mummer --snps sp2_T.snps --reference Orbicella_faveolata_cds.fna --type SNP --input-header --no-Ns > sp2.vcf\n\n# Get stats on VCF files.\nall2vcf stats --vcf sp1.vcf"
  },
  {
    "objectID": "orbicella_quarto_nb.html#troubleshooting-all2vcf",
    "href": "orbicella_quarto_nb.html#troubleshooting-all2vcf",
    "title": "Orbicella Analysis of Hybridization- Medina Lab Penn State University",
    "section": "Troubleshooting all2vcf",
    "text": "Troubleshooting all2vcf\nmargin-header: |  So something went wrong when I tried to convert the .snp output from Mummer into VCF format. The chromosome and position data is present but I don’t see genotypes.\n\nbcftools view -h sp1.vcf  | awk '/INFO/ || /FORMAT/'\n\nIt looks like I don’t have a FORMAT or SAMPLE column. I only have the first 8 columns.\nUpdate! Raul says there are no homologous loci since I have haploid genome assemblies. Basically, I need to add the FORMAT column (“GT”) and SAMPLE column titled (“Ofav”, “Oann”, or “Ofrank”). The sample column will contain “0|0 if the sample allele matches the ref or”1|1” if not. Then I should be ready to merge.\nI wrote a python script to accomplish this (VCF_add_columns.ipynb).\nIt seems to have worked, except I noticed that the SNP ID:LENGTH is occupying column 8 which interferes with the indexing scheme. Ask if I should delete this information or move it the third column.\n\n\n\nimage"
  },
  {
    "objectID": "orbicella_quarto_nb.html#demo-explore-vcf-files-with-bcftools-httpseriqande.github.ioeca-bioinf-handbookbasic-handling-of-vcf-files.html",
    "href": "orbicella_quarto_nb.html#demo-explore-vcf-files-with-bcftools-httpseriqande.github.ioeca-bioinf-handbookbasic-handling-of-vcf-files.html",
    "title": "Orbicella Analysis of Hybridization- Medina Lab Penn State University",
    "section": "Demo: Explore vcf files with bcftools: https://eriqande.github.io/eca-bioinf-handbook/basic-handling-of-vcf-files.html",
    "text": "Demo: Explore vcf files with bcftools: https://eriqande.github.io/eca-bioinf-handbook/basic-handling-of-vcf-files.html\n\n# Who is in the VCF file?\nbcftools query -l chinook-32-3Mb.vcf.gz\n# How many variants?\nbcftools stats chinook-32-3Mb.vcf.gz\n\n# Where are these variants? Where does it start/end?\nbcftools query -f '%CHROM\\t%POS\\n' chinook-32-3Mb.vcf.gz\nbcftools query -f '%CHROM\\t%POS\\n' chinook-32-3Mb.vcf.gz | head \nbcftools query -f '%CHROM\\t%POS\\n' chinook-32-3Mb.vcf.gz | tail\n\n# show the whole file from the top (use show just the first 10 lines)\nbcftools view chinook-32-3Mb.vcf.gz | head\n\n# show just the header with -h.  Here look at just the last 10 lines of the header\nbcftools view -h chinook-32-3Mb.vcf.gz | tail\n\n# show the variants themslves (no header) with -H\nbcftools view -H chinook-32-3Mb.vcf.gz | head\n\n# Merge files. See genotypes with 100% of individuals having at least one read at the genotype.\n# make file with first three samples\nbcftools view -Oz -s DPCh_plate1_A05_S5,DPCh_plate1_A06_S6,DPCh_plate1_A11_S11 chinook-32-3Mb.vcf.gz > first3.vcf.gz\n\n# make another with the last three samples\nbcftools view -Oz -s DPCh_plate1_H06_S90,DPCh_plate1_H11_S95,DPCh_plate1_H12_S96 chinook-32-3Mb.vcf.gz > last3.vcf.gz\n\n# merging requires that the files be indexed\n\nbcftools index first3.vcf.gz\nbcftools index last3.vcf.gz\n\n# merge those into a file with 6 samples\nbcftools merge -Oz first3.vcf.gz last3.vcf.gz > 6-samples.vcf.gz\n\n# Fraction of missing sites less than X\nbcftools view -i 'F_MISSING < 0.0' chinook-32-3Mb.vcf.gz | bcftools stats - | awk '/^SN/'"
  },
  {
    "objectID": "orbicella_quarto_nb.html#merge-vcf-files-to-represent-shared-snp-sites-across-the-3-species.",
    "href": "orbicella_quarto_nb.html#merge-vcf-files-to-represent-shared-snp-sites-across-the-3-species.",
    "title": "Orbicella Analysis of Hybridization- Medina Lab Penn State University",
    "section": "Merge VCF Files to represent shared SNP sites across the 3 species.",
    "text": "Merge VCF Files to represent shared SNP sites across the 3 species.\nhttps://github.com/sbslee/fuc https://pyvcf.readthedocs.io/en/latest/\nI will test merge the three files and cross reference the new file against the three original files at 10 evenly spaced SNPS. This will probably require another script. See VCF_add_columns.py\nMake sure to check the efficacy of this by cross referencing the merged file at certain SNPS against the original files.\nMy VCF script almost works but I am getting this error KeyError(f”{not_found} not in index”). This seems like a potential solution: https://stackoverflow.com/questions/51091132/pandas-and-scikit-learn-keyerror-not-in-index\nBut the error arises when I call the prebuilt merge function from pyvcf. So I am not sure how to make this change."
  },
  {
    "objectID": "orbicella_quarto_nb.html#prepare-outgroup-genome.",
    "href": "orbicella_quarto_nb.html#prepare-outgroup-genome.",
    "title": "Orbicella Analysis of Hybridization- Medina Lab Penn State University",
    "section": "Prepare outgroup genome.",
    "text": "Prepare outgroup genome.\nMy second task is to isolate the Cyphastrea coral reads from the rest of the microbiome reads. This can be broken down into a number of steps. The first of which is running Psytrans: https://github.com/sylvainforet/psytrans.\nThis work is being done on the Medina lab server ‘argonaute’ and can be found in the directory /home/vpg5102/Orbicella. The Symbiodiniaceae genomes can be located at /home/rag5851/Symbiodiniaceae_genomes.\nThe psytrans documentation isn’t that great, so Raul offered me some really helpful practical advice in setting up the files for the filtering of symbiont reads. First, I need to concatenate the coral and symbiont reference genomes into a single file.\nspecies1 is the host. species2 is the symbiont. Rename each of the sequence components (i.e. >scaffold.fasta) to include the species pre-fix.\nOnce these steps are completed, run BLAST to identify which sequences are coral vs. symbiont. Run BLAST with these flags: -output 6 (gives tabulated table) -evalue 1 e-5 -out species1species2_blastResults.txt\n\n# Get Orbicella genomes for cnidarian database\ncurl https://www.ncbi.nlm.nih.gov/assembly/GCA_002042975.1\ncurl https://www.ncbi.nlm.nih.gov/assembly/GCA_001896105.1\n\n# Add a broader selection of other corals as well.\n# reefgenomics.org\nfaveolata\nS.pis\nA. dig\nA. tenuis\nP. australiensis\nP. dae\nPorites lutea\n\n# So I accidentally added this file to my db: GCF_002042975.1_ofav_dov_v1_cds_from_genomic.fna. Not sure if that will impact the blast results. \n\n\n# Add species prefix before concatenating references.\n# For concatenated host genomes.\nsed “s/^>/>species1_/g”\n\n# For concatenated symbiont genomes.\nsed “s/^>/>species2_/g”\n\n# Now concatenate Coral/Symbiont Genomes\ncat *.fna > species1_species2_blastdb.fasta\n\n\n# Creat Blastdb and designate database type\nmakeblastdb -in species1_species2_blastdb.fasta -dbtype nuc\n\n#BLAST search query of cyphastrea metagenome against database. IGNORE\nblastn -query Cyphastrea_blast/Cyphastrea_metagenome.scaffolds.fasta -db species1_species2_blastdb.fasta -outfmt 6 -evalue 1e-5 -out Species1Species2_blastResults.txt\n\n# CORRECT CODE. 10/26 Looking at this more closely the code should be:\n\nblastn -query Cyphastrea_metagenome.scaffolds.fasta -db Cyphastrea_blast/species1_species2_blastdb.fasta -outfmt 6 -evalue 1e-5 -out species1species2_blastResults.txt\n\nI am re-running BLAST 10/26/22.\nThen run the psytrans code to separate the coral data from symbiont data.\n\n# Make a screen. Then run psytrans. 10/16/22. \n# screen -S psytrans_attempt\n# Type \"screen [-d] -r [pid.]tty.host\" to resume\n# python psytrans.py [QUERIES] [-b BLASTRESULTSFILE] [OPTIONS]\npython psytrans-master/psytrans.py Cyphastrea_metagenome.scaffolds.fasta -b Species1Species2_blastResults.txt -t tmp -p 8\n\n# updated psytrans command 10/26\npython ../psytrans-master/psytrans.py ../Cyphastrea_metagenome.scaffolds.fasta -b species1species2_blastResults.txt -t tmp -p 8 -v\n\nApparently ‘maketrans’ is deprecated. I have to modify the script. I just changed string.maketrans to str.maketrans.\nWhen I run psytrans, the output folder remains empty… Looking at the python script, I have to make sure the “s” in “species” is lowercase."
  },
  {
    "objectID": "orbicella_quarto_nb.html#final-filtering-step-with-blobtools-to-remove-traces-of-bacterial-reads.",
    "href": "orbicella_quarto_nb.html#final-filtering-step-with-blobtools-to-remove-traces-of-bacterial-reads.",
    "title": "Orbicella Analysis of Hybridization- Medina Lab Penn State University",
    "section": "Final filtering step with Blobtools to remove traces of bacterial reads.",
    "text": "Final filtering step with Blobtools to remove traces of bacterial reads."
  },
  {
    "objectID": "VCF_combine.html",
    "href": "VCF_combine.html",
    "title": "",
    "section": "",
    "text": "vcf_open_file = open('')\nfrom csv import reader\ngoogle_read = reader(google_open_file)\nvcf_data = list(vcf_read)"
  },
  {
    "objectID": "orbicella_quarto_nb.html#rerun-pipeline-with-correct-assemblies.",
    "href": "orbicella_quarto_nb.html#rerun-pipeline-with-correct-assemblies.",
    "title": "Orbicella Analysis of Hybridization- Medina Lab Penn State University",
    "section": "Rerun pipeline with correct assemblies.",
    "text": "Rerun pipeline with correct assemblies.\nI mistakenly used the CDS assemblies when I should have used the nucleotide assemblies. I also need to double check that my coral database has nucleotide assembly files."
  },
  {
    "objectID": "orbicella_quarto_nb.html#filter-bacterial-sequences",
    "href": "orbicella_quarto_nb.html#filter-bacterial-sequences",
    "title": "Orbicella Analysis of Hybridization- Medina Lab Penn State University",
    "section": "Filter Bacterial Sequences",
    "text": "Filter Bacterial Sequences\nWe are using blobtools which has great documentation and integration for mapping, visualization of assembly, and partitioning of sequences.\nWe are using workflow-A for denovo genomes since that is what the Cyphastrea metagenome is. These are the steps:\n\nConstruction a BlobDB data structure based on input files\nVisualisation of assembly and generation of tabular output. See “my first blob plot” tutorial.\nPartitioning of sequence IDs based on user-defined parameters informed by the visualisations\nPartitioning of paired-end reads based on their mapping behaviour to sequence partitions\nResulting reads are then assembled by partition and the assemblies can be screened again using the workflow.\n\nimage\nI need an assembly file, a coverage file (I don’t know where to get this. check directory where I originally got the genome from), and a hits file (e.g. the blast output).\nCreate a blobDB.I am using pre-formatted db files from ncbi.\n\n#!/bin/bash\nfor i in {0..10..1}\ndo\n    wget https://ftp.ncbi.nlm.nih.gov/blast/db/\"nt.0$i.tar.gz\"\ndone\n# gunzip the files\n\nOkay so far, as of 10/28, I have the first two. Now I need to run blast to create the hits file. I’m going to use megablast since it is used to find very similar sequences. I want to match the microbial sequences in our metagenome to the sequences in the pre-formatted database I just downloaded. Blobtools recommended these parameters for a good tradeoff between speed and accuracy.\n\nblastn \\\n-task megablast \\\n-query Cyphastrea_metagenome.scaffolds.fasta \\\n-db blobdb \\\n-outfmt '6 qseqid staxids bitscore std' \\\n-max_target_seqs 1 \\\n-max_hsps 1 \\\n-num_threads 16 \\\n-evalue 1e-25 \\\n-out assembly.vs.blobdb.mts1.hsp1.1e25.megablast.out\n\nCreate a blobplot\n\n./blobtools create \\\n -i Cyphastrea_metagenome.scaffolds.fasta \\\n -b 1107374.scaffolds.sam.gz \\\n -t assembly.vs.blobdb.mts1.hsp1.1e25.megablast.out \\\n -o my_first_blobplot\n\nCreate a view of a blobDB file\n\n./blobtools view \\\n -i my_first_blobplot.blobDB.json \\\n -o \n\nInspect output\n\ngrep '^##' my_first_blobplot.blobDB.table.txt ; \\\n grep -v '^##' my_first_blobplot.blobDB.table.txt | \\\n column -t -s $'\\t'\n\nCreate a blobplot\n\n./blobtools plot \\\n -i blobDB.json \\\n -o \n\n\nblobtools covplot  -i BLOBDB -c COV\nblobtools map2cov\nblobtools seqfilter\nblobtools bamfilter\nblobtools taxify"
  },
  {
    "objectID": "orbicella_quarto_nb.html#create-newik-tree-for-input-to-dsuite",
    "href": "orbicella_quarto_nb.html#create-newik-tree-for-input-to-dsuite",
    "title": "Orbicella Analysis of Hybridization- Medina Lab Penn State University",
    "section": "Create Newik Tree for input to DSUITE",
    "text": "Create Newik Tree for input to DSUITE\nSince the phylogeny is already known, we can just construct the tree like this. Make sure the names here match the names in the other files. (Cyph,(Ofav,(Oann,Ofrank))); If I wanted to add branch lengths than I would add a semicolon and branch lengths.\n\nabbababba_tree<-(Cyph,(Ofav,(Oann,Ofrank)));\n\n# If I need to read the tree\nape::read.tree(abbababba_tree)\n# Save the tree to a text file\nape::write.tree(tree, file='orbicella_cyph_tree.txt')"
  },
  {
    "objectID": "orbicella_quarto_nb.html#abba-babba-analysis",
    "href": "orbicella_quarto_nb.html#abba-babba-analysis",
    "title": "Orbicella Analysis of Hybridization- Medina Lab Penn State University",
    "section": "ABBA-BABBA Analysis",
    "text": "ABBA-BABBA Analysis\nDsuite dtrios Review dog paper that eric sent and how they visualize the evidence of hybridization from ABBA BABBA analysis How do we know when the test is significant or not Read the fish papers that eric sent to colin and I"
  },
  {
    "objectID": "VCF_add_columns.html",
    "href": "VCF_add_columns.html",
    "title": "",
    "section": "",
    "text": "# automate the reading and formatting of data from multiple input files.\nvcf1 = []\nvcf2 = []\n\nfor i in range(1,3):\n    vcf = open('vcf'+str(i)+'.vcf')\n    # Read by line\n    vcf = vcf.readlines()\n    # Add header row\n    vcf[:0] = [\"CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\tSAMPLE\"]\n    # Split by tabs. Create list of lists\n    vcf = [line.split('\\t') for line in vcf]\n    if i == 1:\n        vcf1.extend(vcf)\n    elif i == 2:\n        vcf2.extend(vcf)\n\nprint(vcf1)\nprint(vcf2)\n\nfor row in vcf1:\n    print(row)\n    print(len(row))\n\n[['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'SAMPLE'], ['g1.t1', '159', '.', 'C', 'T', '.', '.', '.', 'g4643.t1:159\\n'], ['g1.t1', '201', '.', 'T', 'C', '.', '.', '.', 'g4643.t1:201\\n'], ['g1.t1', '210', '.', 'T', 'A', '.', '.', '.', 'g4643.t1:210\\n'], ['g1.t1', '332', '.', 'C', 'T', '.', '.', '.', 'g4643.t1:332\\n'], ['g1.t1', '883', '.', 'A', 'T', '.', '.', '.', 'g4643.t1:979\\n'], ['g10.t1', '74', '.', 'A', 'G', '.', '.', '.', 'g19112.t1:74\\n'], ['g10.t1', '97', '.', 'A', 'G', '.', '.', '.', 'g19112.t1:97\\n'], ['g10.t1', '144', '.', 'A', 'G', '.', '.', '.', 'g19112.t1:144\\n'], ['g10.t1', '146', '.', 'A', 'G', '.', '.', '.', 'g19112.t1:146\\n'], ['g10.t1', '147', '.', 'G', 'A', '.', '.', '.', 'g19112.t1:147\\n']]\n[['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'SAMPLE'], ['g9999.t1', '6557', '.', 'G', 'A', '.', '.', '.', 'g58886.t1:5357,g85269.t1:6542\\n'], ['g9999.t1', '6820', '.', 'A', 'G', '.', '.', '.', 'g58886.t1:5620,g85269.t1:6805\\n'], ['g9999.t1', '6821', '.', 'A', 'G', '.', '.', '.', 'g58886.t1:5621,g85269.t1:6806\\n'], ['g9999.t1', '6830', '.', 'T', 'C', '.', '.', '.', 'g58886.t1:5630,g85269.t1:6815\\n'], ['g9999.t1', '6859', '.', 'C', 'G', '.', '.', '.', 'g58886.t1:5659,g85269.t1:6844\\n'], ['g9999.t1', '6862', '.', 'A', 'C', '.', '.', '.', 'g58886.t1:5662,g85269.t1:6847\\n'], ['g9999.t1', '6874', '.', 'C', 'A', '.', '.', '.', 'g58886.t1:5674,g85269.t1:6859\\n'], ['g9999.t1', '6889', '.', 'G', 'A', '.', '.', '.', 'g58886.t1:5689,g85269.t1:6874\\n'], ['g9999.t1', '7011', '.', 'T', 'C', '.', '.', '.', 'g58886.t1:5811\\n'], ['g9999.t1', '7020', '.', 'G', 'C', '.', '.', '.', 'g58886.t1:5820\\n']]\n['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'SAMPLE']\n10\n['g1.t1', '159', '.', 'C', 'T', '.', '.', '.', 'g4643.t1:159\\n']\n9\n['g1.t1', '201', '.', 'T', 'C', '.', '.', '.', 'g4643.t1:201\\n']\n9\n['g1.t1', '210', '.', 'T', 'A', '.', '.', '.', 'g4643.t1:210\\n']\n9\n['g1.t1', '332', '.', 'C', 'T', '.', '.', '.', 'g4643.t1:332\\n']\n9\n['g1.t1', '883', '.', 'A', 'T', '.', '.', '.', 'g4643.t1:979\\n']\n9\n['g10.t1', '74', '.', 'A', 'G', '.', '.', '.', 'g19112.t1:74\\n']\n9\n['g10.t1', '97', '.', 'A', 'G', '.', '.', '.', 'g19112.t1:97\\n']\n9\n['g10.t1', '144', '.', 'A', 'G', '.', '.', '.', 'g19112.t1:144\\n']\n9\n['g10.t1', '146', '.', 'A', 'G', '.', '.', '.', 'g19112.t1:146\\n']\n9\n['g10.t1', '147', '.', 'G', 'A', '.', '.', '.', 'g19112.t1:147\\n']\n9\n\n\n\n# Try this: https://www.geeksforgeeks.org/appending-to-list-in-python-dictionary/\n# This works! Now make it scalable.\n#dict1 = {'CHROM':[],'POS':[], 'ID':[], 'REF':[], 'ALT':[], 'QUAL':[], 'FILTER':[], 'INFO':[], 'FORMAT':[], 'SAMPLE':[]}\n#keys = ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'EXTRA','FORMAT', 'SAMPLE']\n\n#for row in vcf1[1:]:\n#    for item in row:\n#        item_index = row.index(item)\n#        # print(item_index) = 0,1,etc.\n#        key = keys[item_index]\n#        if key in dict1:\n#            dict1[key].append(item)\n#print(dict1)\n# This is a great way to make dictionary from scratch\n#    for key in keys:\n#        test_dict[str(key)]= 1\n\n\n\ndict1 = {'CHROM':[],'POS':[], 'ID':[], 'REF':[], 'ALT':[],'QUAL':[], 'FILTER':[], 'INFO':[], 'FORMAT':[], 'SAMPLE':[]}\ndict2 = {'CHROM':[],'POS':[], 'ID':[], 'REF':[], 'ALT':[],'QUAL':[], 'FILTER':[], 'INFO':[], 'FORMAT':[], 'SAMPLE':[]}\nsamples = [vcf1, vcf2]\nkeys = ['CHROM', 'POS', 'ID', 'REF', 'ALT','QUAL', 'FILTER', 'INFO','FORMAT', 'SAMPLE']\n\nfor sample in samples:\n    for row in sample[1:]:\n        row[2] = row[-1]\n        row.pop(-1)\n        #print(\"TEST\", row)\n        ref = row[3]\n        alt = row[4]\n        row.append('GT')\n        if ref == alt:\n            row.append('0|0')\n        else:\n            row.append('1|1')\n        for i in range(0,10):#row:\n            #item_index = row.index(i)\n            key = keys[i]#item_index]\n            print(i, key)#item_index, key)\n            if sample == vcf1:\n                dict0 = dict1\n            else:\n                dict0 = dict2\n            if key in dict0:\n                dict0[key].append(row[i])\n                \nfor key in dict1:\n    print(key, len(dict1[key]), dict1[key])\n\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\n0 CHROM\n1 POS\n2 ID\n3 REF\n4 ALT\n5 QUAL\n6 FILTER\n7 INFO\n8 FORMAT\n9 SAMPLE\nCHROM 10 ['g1.t1', 'g1.t1', 'g1.t1', 'g1.t1', 'g1.t1', 'g10.t1', 'g10.t1', 'g10.t1', 'g10.t1', 'g10.t1']\nPOS 10 ['159', '201', '210', '332', '883', '74', '97', '144', '146', '147']\nID 10 ['g4643.t1:159\\n', 'g4643.t1:201\\n', 'g4643.t1:210\\n', 'g4643.t1:332\\n', 'g4643.t1:979\\n', 'g19112.t1:74\\n', 'g19112.t1:97\\n', 'g19112.t1:144\\n', 'g19112.t1:146\\n', 'g19112.t1:147\\n']\nREF 10 ['C', 'T', 'T', 'C', 'A', 'A', 'A', 'A', 'A', 'G']\nALT 10 ['T', 'C', 'A', 'T', 'T', 'G', 'G', 'G', 'G', 'A']\nQUAL 10 ['.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\nFILTER 10 ['.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\nINFO 10 ['.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\nFORMAT 10 ['GT', 'GT', 'GT', 'GT', 'GT', 'GT', 'GT', 'GT', 'GT', 'GT']\nSAMPLE 10 ['1|1', '1|1', '1|1', '1|1', '1|1', '1|1', '1|1', '1|1', '1|1', '1|1']\n\n\n\nfrom fuc import pyvcf\n# Now I need to figure out how to import: from fuc import pyvcf\nvf1 = pyvcf.VcfFrame.from_dict([], dict1)\nvf2 = pyvcf.VcfFrame.from_dict([], dict2)\nfinal_vf = pyvcf.merge([vf1, vf2]).df\nprint(final_vf)\n#ofav = pyvcf.VcfFrame.from_dict([], dict1)\n#oann = pyvcf.VcfFrame.from_dict([], dict2)\n#ofrank = pyvcf.VcfFrame.from_dict([], dict3)\n#pyvcf.merge([ofav, oann, ofrank]).df\n\nModuleNotFoundError: No module named 'fuc'"
  }
]