
---
title: "Orbicella Analysis of Hybridization- Medina Lab Penn State University"
author: "Vanessa Garcia, advised by Eric Crandall"
date: "2022-9-28"
format:
  html:
    toc: true
    html-math-method: katex
    css: styles.css
    toc-depth: 3
---

body-header: | 
  This page brought to you by <https://www.eurekalert.org/multimedia/927876>
margin-header: |
  ![image](177197_web.jpeg)

We are running an ABBA-BABA test for hybridaztion in the Orbicella species complex. The test requires a VCF file containing variants for each species against a reference (in our case, we will use the outgroup Cyphastrea as the reference), a species tree in Newik format, and a file specifying the sample-name/species pair. I was provided with genomes for O.faveolata, O. annularis, and O. franksi. I was also provided with a metagenome for Cyphastrea. 

Right now, my first task is to create/find a pipeline to merge the VCF files produced from the pairwise SNP-calling in MUMmer(nucmer) into a single VCF file of SNP sites shared between the three species.

## Variant Calling
We are conducting variant calling with Nucmer because it is a fast and efficient tool for variant calling between two genome assemblies. Raul said it is the only tool he is aware of for aligning multiple sequences against multiple sequences.

```{bash}
#| eval: false 
#| #Put this at the beginning of every chunk so it knows not to run

# This code calls the SNPs between the query and ref (O.fav). The
# ref will later be changed to Cyphastrea.

nucmer -c 100 -p sp1 Orbicella_faveolata_cds.fna Orbicella_annularis_cds.fna
nucmer -c 100 -p sp2 Orbicella_faveolata_cds.fna Orbicella_franksi_cds.fna
delta-filter -r -q sp1.delta > sp1.filter
delta-filter -r -q sp2.delta > sp2.filter

# Option -T is required for input to all2vcf program
show-snps -T sp1.filter > sp1_T.snps
show-snps -T sp2.filter > sp2_T.snps

```

Nucmer only outputs .snps files, so I am using this script to transform the data into VCF format: https://github.com/MatteoSchiavinato/all2vcf

```{bash}
#| eval: false
./all2vcf mummer --snps sp1_T.snps --reference Orbicella_faveolata_cds.fna --type SNP --input-header --no-Ns > sp1.vcf
./all2vcf mummer --snps sp2_T.snps --reference Orbicella_faveolata_cds.fna --type SNP --input-header --no-Ns > sp2.vcf

# Get stats on VCF files.
all2vcf stats --vcf sp1.vcf
```

Make sure to run final pipeline with correct assemblies (nuc.fna.gz).

I mistakenly used the CDS assemblies when I should have used the nucleotide assemblies. I also need to double check that my coral database has nucleotide assembly files.

### Editing VCF Files

margin-header: |
  ![image](New Note.jpeg)
So something went wrong when I tried to convert the .snp output from Mummer into VCF format. The chromosome and position data is present but I don't see genotypes.

```{bash}
#| eval: false
bcftools view -h sp1.vcf  | awk '/INFO/ || /FORMAT/'
```

It looks like I don't have a FORMAT or SAMPLE column. I only have the first 8 columns.

Update! Raul says there are no homologous loci since I have haploid genome assemblies. Basically, I need to add the FORMAT column ("GT") and SAMPLE column titled ("Ofav", "Oann", or "Ofrank"). The sample column will contain "0|0 if the sample allele matches the ref or "1|1" if not. Then I should be ready to merge.

I wrote a python script to accomplish this (VCF_add_columns.ipynb).

It seems to have worked, except I noticed that the SNP ID:LENGTH is occupying column 8 which interferes with the indexing scheme. Ask if I should delete this information or move it the third column.

![image](QUAL FILTER INFO.jpeg)

### Merge VCF Files to represent shared SNP sites across the 3 species.
https://github.com/sbslee/fuc
https://pyvcf.readthedocs.io/en/latest/

I will test merge the three files and cross reference the new file against the three original files at 10 evenly spaced SNPS. This will probably require another script. See VCF_add_columns.py

Make sure to check the efficacy of this by cross referencing the merged file at certain SNPS against the original files.

My VCF script almost works but I am getting this error KeyError(f"{not_found} not in index"). This seems like a potential solution: https://stackoverflow.com/questions/51091132/pandas-and-scikit-learn-keyerror-not-in-index

But the error arises when I call the prebuilt merge function from pyvcf. So I am not sure how to make this change.

### Demo: Explore vcf files with bcftools: https://eriqande.github.io/eca-bioinf-handbook/basic-handling-of-vcf-files.html
```{bash}
#| eval: false
# Who is in the VCF file?
bcftools query -l chinook-32-3Mb.vcf.gz
# How many variants?
bcftools stats chinook-32-3Mb.vcf.gz

# Where are these variants? Where does it start/end?
bcftools query -f '%CHROM\t%POS\n' chinook-32-3Mb.vcf.gz
bcftools query -f '%CHROM\t%POS\n' chinook-32-3Mb.vcf.gz | head 
bcftools query -f '%CHROM\t%POS\n' chinook-32-3Mb.vcf.gz | tail

# show the whole file from the top (use show just the first 10 lines)
bcftools view chinook-32-3Mb.vcf.gz | head

# show just the header with -h.  Here look at just the last 10 lines of the header
bcftools view -h chinook-32-3Mb.vcf.gz | tail

# show the variants themslves (no header) with -H
bcftools view -H chinook-32-3Mb.vcf.gz | head

# Merge files. See genotypes with 100% of individuals having at least one read at the genotype.
# make file with first three samples
bcftools view -Oz -s DPCh_plate1_A05_S5,DPCh_plate1_A06_S6,DPCh_plate1_A11_S11 chinook-32-3Mb.vcf.gz > first3.vcf.gz

# make another with the last three samples
bcftools view -Oz -s DPCh_plate1_H06_S90,DPCh_plate1_H11_S95,DPCh_plate1_H12_S96 chinook-32-3Mb.vcf.gz > last3.vcf.gz

# merging requires that the files be indexed

bcftools index first3.vcf.gz
bcftools index last3.vcf.gz

# merge those into a file with 6 samples
bcftools merge -Oz first3.vcf.gz last3.vcf.gz > 6-samples.vcf.gz

# Fraction of missing sites less than X
bcftools view -i 'F_MISSING < 0.0' chinook-32-3Mb.vcf.gz | bcftools stats - | awk '/^SN/'
```


## Prepare Cyphastrea (outgroup) genome. 

My second task is to isolate the Cyphastrea coral reads from the rest of the microbiome reads. This can be broken down into a number of steps. The first of which is running Psytrans: https://github.com/sylvainforet/psytrans.

This work is being done on the Medina lab server 'argonaute' and can be found in the directory /home/vpg5102/Orbicella. The Symbiodiniaceae genomes can be located at /home/rag5851/Symbiodiniaceae_genomes.

The psytrans documentation isn't that great, so Raul offered me some really helpful practical advice in setting up the files for the filtering of symbiont reads. First, I need to concatenate the coral and symbiont reference genomes into a single file.

species1 is the host. species2 is the symbiont. Rename each of the sequence components (i.e. >scaffold.fasta) to include the species pre-fix.

Once these steps are completed, run BLAST to identify which sequences are coral vs. symbiont. Run BLAST with these flags:
-output 6 (gives tabulated table)
-evalue 1 e-5
-out species1species2_blastResults.txt


```{bash}
#| eval: false
# Get Orbicella genomes for cnidarian database
curl https://www.ncbi.nlm.nih.gov/assembly/GCA_002042975.1
curl https://www.ncbi.nlm.nih.gov/assembly/GCA_001896105.1

# Add a broader selection of other corals as well.
# reefgenomics.org
faveolata
S.pis
A. dig
A. tenuis
P. australiensis
P. dae
Porites lutea

# I accidentally added this file to my db: GCF_002042975.1_ofav_dov_v1_cds_from_genomic.fna. Not sure if that will impact the blast results. 

```


```{bash}
#| eval: false
# Add species prefix before concatenating references.
# For concatenated host genomes.
sed “s/^>/>species1_/g”

# For concatenated symbiont genomes.
sed “s/^>/>species2_/g”

# Now concatenate Coral/Symbiont Genomes
cat *.fna > species1_species2_blastdb.fasta
```

```{bash}
#| eval: false
# Creat Blastdb and designate database type
makeblastdb -in species1_species2_blastdb.fasta -dbtype nuc

#BLAST search query of cyphastrea metagenome against database
blastn -query Cyphastrea_blast/Cyphastrea_metagenome.scaffolds.fasta -db species1_species2_blastdb.fasta -outfmt 6 -evalue 1e-5 -out Species1Species2_blastResults.txt

# CORRECT CODE. 10/26 Looking at this more closely the code should be:

blastn -query Cyphastrea_metagenome.scaffolds.fasta -db Cyphastrea_blast/species1_species2_blastdb.fasta -outfmt 6 -evalue 1e-5 -out species1species2_blastResults.txt
```

I am re-running BLAST 10/26/22.

### Psytrans code to separate the coral data from symbiont data.

```{bash}
#| eval: false
# Make a screen. Then run psytrans. 10/16/22. 
# screen -S psytrans_attempt
# Type "screen [-d] -r [pid.]tty.host" to resume
# python psytrans.py [QUERIES] [-b BLASTRESULTSFILE] [OPTIONS]
python psytrans-master/psytrans.py Cyphastrea_metagenome.scaffolds.fasta -b Species1Species2_blastResults.txt -t tmp -p 8

# updated psytrans command 10/26
python ../psytrans-master/psytrans.py ../Cyphastrea_metagenome.scaffolds.fasta -b species1species2_blastResults.txt -t tmp -p 8 -v
```


Apparently 'maketrans' is deprecated. I have to modify the script. I just changed string.maketrans to str.maketrans.

When I run psytrans, the output folder remains empty... Looking at the python script, I have to make sure the "s" in "species" is lowercase.

### Removing Bacterial Sequences with Blobtools

We are using blobtools which has great documentation and integration for mapping, visualization of assembly, and partitioning of sequences.

We are using workflow-A for denovo genomes since that is what the Cyphastrea metagenome is. These are the steps:

1. Construction a BlobDB data structure based on input files
2. Visualisation of assembly and generation of tabular output. See "my first blob plot" tutorial.
3. Partitioning of sequence IDs based on user-defined parameters informed by the visualisations
4. Partitioning of paired-end reads based on their mapping behaviour to sequence partitions
5. Resulting reads are then assembled by partition and the assemblies can be screened again using the workflow.

[image](blobtools.png)

I need an assembly file, a coverage file (I don't know where to get this. check directory where I originally got the genome from), and a hits file (e.g. the blast output).

Create a blobDB.I am using pre-formatted db files from ncbi.
```{bash}
#| eval: false
#!/bin/bash
for i in {0..10..1}
do
	wget https://ftp.ncbi.nlm.nih.gov/blast/db/"nt.0$i.tar.gz"
done
# gunzip the files

```

Okay so far, as of 10/28, I have the first two. Now I need to run blast to create the hits file. I'm going to use megablast since it is used to find very similar sequences. I want to match the microbial sequences in our metagenome to the sequences in the pre-formatted database I just downloaded. Blobtools recommended these parameters for a good tradeoff between speed and accuracy.

```{bash}
#| eval: false
blastn \
-task megablast \
-query Cyphastrea_metagenome.scaffolds.fasta \
-db blobdb \
-outfmt '6 qseqid staxids bitscore std' \
-max_target_seqs 1 \
-max_hsps 1 \
-num_threads 16 \
-evalue 1e-25 \
-out assembly.vs.blobdb.mts1.hsp1.1e25.megablast.out
```

Create a blobplot
```{bash}
#| eval: false
./blobtools create \
 -i Cyphastrea_metagenome.scaffolds.fasta \
 -b 1107374.scaffolds.sam.gz \
 -t assembly.vs.blobdb.mts1.hsp1.1e25.megablast.out \
 -o my_first_blobplot
```

Create a view of a blobDB file
```{bash}
#| eval: false
./blobtools view \
 -i my_first_blobplot.blobDB.json \
 -o 
```

Inspect output
```{bash}
#| eval: false
grep '^##' my_first_blobplot.blobDB.table.txt ; \
 grep -v '^##' my_first_blobplot.blobDB.table.txt | \
 column -t -s $'\t'
```

Create a blobplot
```{bash}
#| eval: false
./blobtools plot \
 -i blobDB.json \
 -o 
```

```{bash}
#| eval: false
blobtools covplot  -i BLOBDB -c COV
blobtools map2cov
blobtools seqfilter
blobtools bamfilter
blobtools taxify

```

## Create Newik Tree for input to DSUITE

Since the phylogeny is already known, we can just construct the tree like this. Make sure the names here match the names in the other files.
(Cyph,(Ofav,(Oann,Ofrank))); If I wanted to add branch lengths than I would add a semicolon and branch lengths.


```{bash}
#| eval: false
abbababba_tree<-(Cyph,(Ofav,(Oann,Ofrank)));

# If I need to read the tree
ape::read.tree(abbababba_tree)
# Save the tree to a text file
ape::write.tree(tree, file='orbicella_cyph_tree.txt')
```


## ABBA-BABBA Analysis
Dsuite
dtrios
Review dog paper that eric sent and how they visualize the evidence of hybridization from ABBA BABBA analysis
How do we know when the test is significant or not
Read the fish papers that eric sent to colin and I

```{R}
# Input: VCF file, Newick tree, sample name file

```

